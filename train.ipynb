{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c89d11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103  Python-3.11.4 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Setup complete  (20 CPUs, 23.7 GB RAM, 74.1/100.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b981d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 1 Stenosis, 9.0ms\n",
      "Speed: 15.2ms preprocess, 9.0ms inference, 67.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "Detections: [{'xyxy': [69.92406463623047, 270.882080078125, 86.36941528320312, 293.2762145996094], 'xywh': [78.14674377441406, 282.07916259765625, 16.445350646972656, 22.394134521484375], 'conf': 0.20134316384792328, 'class': 0}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO  # if using ultralytics\n",
    "import cv2\n",
    "\n",
    "# ---- helper: reverse letterbox (common for YOLO) ----\n",
    "def scale_coords_from_letterbox(pred_xyxy, orig_shape, inp_shape):\n",
    "    \"\"\"\n",
    "    Map predicted xyxy boxes from the model input (possibly letterboxed) back to original image size.\n",
    "    pred_xyxy: Nx4 array of [x1,y1,x2,y2] in model input coordinates (pixels)\n",
    "    orig_shape: (height, width)\n",
    "    inp_shape: (height, width) used for model input\n",
    "    Returns: Nx4 array of boxes in original image pixel coords (clipped)\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = orig_shape\n",
    "    inp_h, inp_w = inp_shape\n",
    "\n",
    "    # compute scale and padding used by letterbox\n",
    "    scale = min(inp_w / orig_w, inp_h / orig_h)\n",
    "    new_w = int(orig_w * scale)\n",
    "    new_h = int(orig_h * scale)\n",
    "    pad_w = (inp_w - new_w) / 2  # left+right total distributed evenly\n",
    "    pad_h = (inp_h - new_h) / 2\n",
    "\n",
    "    # remove padding, then divide by scale\n",
    "    boxes = pred_xyxy.copy().astype(np.float32)\n",
    "    boxes[:, [0,2]] -= pad_w\n",
    "    boxes[:, [1,3]] -= pad_h\n",
    "    boxes[:, :4] /= scale\n",
    "\n",
    "    # clip to image\n",
    "    boxes[:, 0] = boxes[:, 0].clip(0, orig_w-1)\n",
    "    boxes[:, 1] = boxes[:, 1].clip(0, orig_h-1)\n",
    "    boxes[:, 2] = boxes[:, 2].clip(0, orig_w-1)\n",
    "    boxes[:, 3] = boxes[:, 3].clip(0, orig_h-1)\n",
    "    return boxes\n",
    "\n",
    "# ---- Run YOLO (Ultralytics) and extract boxes ----\n",
    "model = YOLO(r'runs\\detect\\train\\weights\\best.pt')   # point to your trained model\n",
    "\n",
    "def detect_and_get_boxes(img_bgr, conf_thresh=0.25):\n",
    "    # img_bgr: original BGR NumPy image\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    # Run model (returns results with boxes in model's input coords)\n",
    "    results = model.predict(source=img_bgr, conf=conf_thresh, imgsz=1280)  # adjust imgsz to what you used\n",
    "    detections = []\n",
    "    for r in results:\n",
    "        if len(r.boxes) == 0:\n",
    "            continue\n",
    "        # r.boxes.xyxy is Nx4 in model input coordinate system\n",
    "        pred_xyxy = r.boxes.xyxy.cpu().numpy()  # Nx4\n",
    "        scores = r.boxes.conf.cpu().numpy()     # Nx\n",
    "        classes = r.boxes.cls.cpu().numpy().astype(int)\n",
    "        # map to original image coords (reverse letterbox)\n",
    "        mapped = scale_coords_from_letterbox(pred_xyxy, (H, W), (r.orig_shape[0], r.orig_shape[1]))\n",
    "        for (x1,y1,x2,y2), s, c in zip(mapped, scores, classes):\n",
    "            detections.append({\n",
    "                'xyxy': [float(x1), float(y1), float(x2), float(y2)],\n",
    "                'xywh': [float((x1+x2)/2), float((y1+y2)/2), float(x2-x1), float(y2-y1)],\n",
    "                'conf': float(s),\n",
    "                'class': int(c)\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "# Example use:\n",
    "img = cv2.imread(r'runs\\detect\\predict\\14_002_5_0025_bmp.rf.debdb2e5cdec339506b1e5944ca03feb.jpg')\n",
    "dets = detect_and_get_boxes(img, conf_thresh=0.2)\n",
    "print(\"Detections:\", dets)\n",
    "# Crop ROI for segmentation:\n",
    "for i, det in enumerate(dets):\n",
    "    x1,y1,x2,y2 = map(int, det['xyxy'])\n",
    "    roi = img[y1:y2, x1:x2]   # crop in original pixel coords\n",
    "    cv2.imwrite(f'roi_{i}.png', roi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d322d",
   "metadata": {},
   "source": [
    "yolo predict \\\n",
    "  model=runs/detect/train/weights/best.pt \\\n",
    "  source=test/images \\\n",
    "  save=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2753dd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
